
import streamlit as st
import pandas as pd
import io, re
from io import BytesIO

st.set_page_config(page_title="TD Checker", page_icon="‚úÖ", layout="wide")

st.title("TD Checker ‚Ä¢ ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö berth_id ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå .dna ‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á")
st.markdown("""
‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå .dna (‡πÑ‡∏î‡πâ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 3 ‡πÑ‡∏ü‡∏•‡πå) ‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á (.txt) ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å td_id (‡πÄ‡∏ä‡πà‡∏ô **Y1, YE, FE, DR**) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
""")

def parse_dna_file(file) -> pd.DataFrame:
    content = file.read()
    try:
        text = content.decode("utf-8", errors="ignore")
    except:
        text = content.decode(errors="ignore")
    lines = text.splitlines()
    in_data = False
    rows = []
    for raw in lines:
        s = raw.strip()
        if s.startswith("** DATA BEGINS HERE **"):
            in_data = True
            continue
        if not in_data:
            continue
        if not s:
            continue
        if s.startswith("Version") or s.startswith("berth_id"):
            continue
        toks = [t.strip() for t in raw.split('\t') if t.strip() != ""]
        if not toks:
            continue
        berth_id = toks[0]
        td_id    = toks[-1]
        if berth_id.startswith("//"):
            continue
        rows.append((berth_id.strip(), td_id.strip()))
    df = pd.DataFrame(rows, columns=["berth_id", "td_id"])
    return df

def load_reference_ids(txt_file) -> set:
    content = txt_file.read()
    try:
        text = content.decode("utf-8", errors="ignore")
    except:
        text = content.decode(errors="ignore")
    tokens = re.split(r"[,\s]+", text.strip())
    return {t for t in tokens if t}

def compare_sets(name: str, dna_set: set, ref_set: set) -> pd.DataFrame:
    missing = sorted(ref_set - dna_set)  # ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏™‡πÄ‡∏õ‡∏Å ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô .dna
    extra   = sorted(dna_set - ref_set)  # ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô .dna ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏™‡πÄ‡∏õ‡∏Å
    matched = sorted(dna_set & ref_set)
    parts = []
    parts += [{"td_id": name, "status": "MISSING_IN_DNA", "berth_id": bid} for bid in missing]
    parts += [{"td_id": name, "status": "EXTRA_IN_DNA",   "berth_id": bid} for bid in extra]
    parts += [{"td_id": name, "status": "MATCHED",        "berth_id": bid} for bid in matched]
    return pd.DataFrame(parts, columns=["td_id", "status", "berth_id"])

dna_files = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå .dna (1‚Äì3 ‡πÑ‡∏ü‡∏•‡πå)", type=["dna","txt"], accept_multiple_files=True)
ref_files = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á (.txt) ‡πÄ‡∏ä‡πà‡∏ô Y1.txt, YE.txt ... (‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ)", type=["txt"], accept_multiple_files=True)

td_input = st.text_input("‡πÉ‡∏™‡πà‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ td_id (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á)", value="Y1 YE FE DR").strip()
td_list = [t for t in td_input.split() if t]

run_btn = st.button("üîé ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô")

if run_btn:
    if not dna_files:
        st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå .dna ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡πÑ‡∏ü‡∏•‡πå")
        st.stop()

    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå .dna
    frames = []
    for f in dna_files:
        try:
            df = parse_dna_file(f)
            frames.append(df)
        except Exception as e:
            st.error(f"‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {f.name} ({e})")
    if not frames:
        st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .dna ‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î")
        st.stop()

    df_all = pd.concat(frames, ignore_index=True)

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á mapping td -> ref_set ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á
    ref_map = {t: set() for t in td_list}
    # ‡πÄ‡∏î‡∏≤ td ‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á: ‡πÄ‡∏ä‡πà‡∏ô Y1.txt -> Y1
    name_map = {}
    for rf in ref_files or []:
        stem = rf.name.rsplit(".",1)[0]
        name_map[stem] = rf

    for td in td_list:
        if td in name_map:
            try:
                # ‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏™‡∏≥‡πÄ‡∏ô‡∏≤‡πÑ‡∏ü‡∏•‡πå (file_uploader ‡πÄ‡∏õ‡πá‡∏ô stream, ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
                ref_bytes = name_map[td].getvalue()
                ref_buf = io.BytesIO(ref_bytes)
                ref_map[td] = load_reference_ids(ref_buf)
            except Exception as e:
                st.warning(f"‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á {name_map[td].name} ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}")
                ref_map[td] = set()
        else:
            ref_map[td] = set()  # ‡πÑ‡∏°‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡πâ td ‡∏ô‡∏µ‡πâ ‡∏à‡∏∞‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô .dna

    # ‡∏à‡∏±‡∏î‡∏ó‡∏≥‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    summary_rows = []
    per_td_results = {}
    for td in td_list:
        dna_ids = set(df_all.loc[df_all["td_id"] == td, "berth_id"].astype(str))
        ref_ids = ref_map.get(td, set()) or set()
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á ‡πÉ‡∏´‡πâ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤ ref = dna (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢)
        if len(ref_ids) == 0:
            ref_ids = dna_ids.copy()
        result_df = compare_sets(td, dna_ids, ref_ids)
        per_td_results[td] = result_df
        n_miss = (result_df["status"] == "MISSING_IN_DNA").sum()
        n_extra = (result_df["status"] == "EXTRA_IN_DNA").sum()
        n_match = (result_df["status"] == "MATCHED").sum()
        summary_rows.append({
            "td_id": td,
            "ref_count": len(ref_ids),
            "dna_count": len(dna_ids),
            "matched": n_match,
            "missing_in_dna": n_miss,
            "extra_in_dna": n_extra
        })

    summary = pd.DataFrame(summary_rows)
    st.subheader("üìä SUMMARY")
    st.dataframe(summary, use_container_width=True)

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Excel ‡πÉ‡∏´‡πâ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        summary.to_excel(writer, sheet_name="SUMMARY", index=False)
        for td, dfres in per_td_results.items():
            sheet = td[:31] if td else "TD"
            dfres.to_excel(writer, sheet_name=sheet, index=False)
    output.seek(0)
    st.download_button(
        label="‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô Excel",
        data=output,
        file_name="td_compare_report.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

    st.success("‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    st.caption("Tip: ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏ó‡∏µ‡∏°‡∏á‡∏≤‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ä‡∏∑‡πà‡∏≠ Y1.txt, YE.txt, FE.txt, DR.txt ‡πÅ‡∏•‡πâ‡∏ß‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå .dna")
