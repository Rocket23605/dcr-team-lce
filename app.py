import streamlit as st
import pandas as pd
import re
from io import BytesIO

# ---------- Page config ----------
st.set_page_config(page_title="TD Checker v3 (Manual)", page_icon="‚úÖ", layout="wide")
st.title("TD Checker v3 ‚Ä¢ ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö berth_id ‡∏î‡πâ‡∏ß‡∏¢‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ó‡∏µ‡πà‡∏ß‡∏≤‡∏á‡πÄ‡∏≠‡∏á (Manual paste)")
st.caption("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå .dna (‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ) + ‡∏Å‡∏≥‡∏´‡∏ô‡∏î td_id ‡πÅ‡∏•‡∏∞‡∏ß‡∏≤‡∏á‡∏•‡∏¥‡∏™‡∏ï‡πå berth_id ‡∏ï‡πà‡∏≠ td ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏î‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô")

# ---------- Helpers ----------
def parse_dna_file(file) -> pd.DataFrame:
    """‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå .dna ‡πÅ‡∏•‡πâ‡∏ß‡∏î‡∏∂‡∏á‡∏Ñ‡∏π‡πà (berth_id, td_id) ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤"""
    content = file.read()
    try:
        text = content.decode("utf-8", errors="ignore")
    except Exception:
        text = content.decode(errors="ignore")
    lines = text.splitlines()

    in_data = False
    rows = []
    for raw in lines:
        s = raw.strip()
        if s.startswith("** DATA BEGINS HERE **"):
            in_data = True
            continue
        if not in_data:
            continue
        if not s:
            continue
        if s.startswith("Version") or s.startswith("berth_id"):
            continue

        # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡πÅ‡∏ó‡πá‡∏ö (‡∏ö‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏õ‡∏ô)
        toks = [t.strip() for t in raw.split("\t") if t.strip() != ""]
        if not toks:
            continue

        berth_id = toks[0]
        td_id    = toks[-1]

        if str(berth_id).startswith("//"):  # ‡∏Ç‡πâ‡∏≤‡∏°‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå
            continue

        rows.append((str(berth_id).strip(), str(td_id).strip()))

    df = pd.DataFrame(rows, columns=["berth_id", "td_id"])
    return df


def parse_manual_list(text: str) -> set:
    """‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ space/comma/newline ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ã‡πá‡∏ï‡∏Ç‡∏≠‡∏á‡∏£‡∏´‡∏±‡∏™"""
    tokens = re.split(r"[,\s]+", (text or "").strip())
    return {t for t in tokens if t}


def compare_sets(name: str, dna_set: set, ref_set: set) -> pd.DataFrame:
    """‡∏Ñ‡∏∑‡∏ô DataFrame ‡∏ó‡∏µ‡πà‡∏°‡∏µ status = MISSING_IN_DNA / EXTRA_IN_DNA / MATCHED"""
    missing = sorted(ref_set - dna_set)  # ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô .dna
    extra   = sorted(dna_set - ref_set)  # ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô .dna ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á
    matched = sorted(dna_set & ref_set)

    parts = []
    parts += [{"td_id": name, "status": "MISSING_IN_DNA", "berth_id": bid} for bid in missing]
    parts += [{"td_id": name, "status": "EXTRA_IN_DNA",   "berth_id": bid} for bid in extra]
    parts += [{"td_id": name, "status": "MATCHED",        "berth_id": bid} for bid in matched]
    return pd.DataFrame(parts, columns=["td_id", "status", "berth_id"])


# ---------- Inputs ----------
dna_files = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå .dna (1‚Äì3 ‡πÑ‡∏ü‡∏•‡πå)", type=["dna", "txt"], accept_multiple_files=True)

td_input = st.text_input("‡πÉ‡∏™‡πà‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ td_id (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á)", value="Y1 YE FE DR").strip()
td_list = [t for t in td_input.split() if t]

st.markdown("### ‡∏ß‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ td (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ space / comma / newline)")
manual_map = {}
cols = st.columns(2)
for i, td in enumerate(td_list):
    with cols[i % 2]:
        manual_map[td] = st.text_area(
            f"{td} ‚Ä¢ ‡∏ß‡∏≤‡∏á `berth_id` ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πÄ‡∏õ‡∏Å",
            key=f"ta_{td}",
            height=120,
            placeholder="‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: A101, A102, A103 ‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ô‡πÄ‡∏ß‡πâ‡∏ô‡∏ß‡∏£‡∏£‡∏Ñ/‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î"
        )

run_btn = st.button("üîé ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô")

# ---------- Processing ----------
if run_btn:
    if not dna_files:
        st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå .dna ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡πÑ‡∏ü‡∏•‡πå")
        st.stop()

    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡πÑ‡∏ü‡∏•‡πå .dna
    frames = []
    for f in dna_files:
        try:
            frames.append(parse_dna_file(f))
        except Exception as e:
            st.error(f"‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {f.name} ({e})")
    if not frames:
        st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .dna ‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î")
        st.stop()

    df_all = pd.concat(frames, ignore_index=True)

    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
    summary_rows = []
    per_td_results = {}
    warn_empty = []

    for td in td_list:
        dna_ids = set(df_all.loc[df_all["td_id"] == td, "berth_id"].astype(str))
        ref_ids = parse_manual_list(manual_map.get(td, ""))

        if len(ref_ids) == 0:
            warn_empty.append(td)

        result_df = compare_sets(td, dna_ids, ref_ids)
        per_td_results[td] = result_df

        n_miss  = (result_df["status"] == "MISSING_IN_DNA").sum()
        n_extra = (result_df["status"] == "EXTRA_IN_DNA").sum()
        n_match = (result_df["status"] == "MATCHED").sum()

        summary_rows.append({
            "td_id": td,
            "ref_count": len(ref_ids),
            "dna_count": len(dna_ids),
            "matched": n_match,
            "missing_in_dna": n_miss,
            "extra_in_dna": n_extra
        })

    if warn_empty:
        st.warning("td ‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ß‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á: " + ", ".join(warn_empty))

    summary = pd.DataFrame(summary_rows)
    st.subheader("üìä SUMMARY")
    st.dataframe(summary, use_container_width=True)

    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ï‡πà‡∏≤‡∏á‡πÅ‡∏ö‡∏ö‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
    st.subheader("üîé ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á (‡∏ï‡πà‡∏≠ td_id)")
    for td, dfres in per_td_results.items():
        col1, col2 = st.columns(2)
        with col1:
            st.markdown(f"**{td} ‚Äî MISSING_IN_DNA** (‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô .dna)")
            st.dataframe(
                dfres.loc[dfres["status"] == "MISSING_IN_DNA", ["berth_id"]],
                use_container_width=True, height=240
            )
        with col2:
            st.markdown(f"**{td} ‚Äî EXTRA_IN_DNA** (‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô .dna ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á)")
            st.dataframe(
                dfres.loc[dfres["status"] == "EXTRA_IN_DNA", ["berth_id"]],
                use_container_width=True, height=240
            )

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Excel ‡πÉ‡∏´‡πâ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        summary.to_excel(writer, sheet_name="SUMMARY", index=False)
        for td, dfres in per_td_results.items():
            sheet = td[:31] if td else "TD"
            dfres.to_excel(writer, sheet_name=sheet, index=False)
    output.seek(0)

    st.download_button(
        label="‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô Excel",
        data=output,
        file_name="td_compare_report.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

    st.success("‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    st.caption("Tips: ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏ó‡∏µ‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏£‡πá‡∏ß ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏™‡πÄ‡∏õ‡∏Å‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ td ‡πÑ‡∏ß‡πâ‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡πâ‡∏ß copy/paste ‡∏•‡∏á‡∏ä‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á td ‡∏ô‡∏±‡πâ‡∏ô ‡πÜ")
