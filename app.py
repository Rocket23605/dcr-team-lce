import streamlit as st
import pandas as pd
import re
from io import BytesIO
from datetime import datetime
import zipfile

# ============== PAGE CONFIG ==============
st.set_page_config(page_title="DVS Tools", page_icon="üß≠", layout="wide")

# ============== HELPERS (shared) ==============
def parse_dna_file(file) -> pd.DataFrame:
    """‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå .dna ‡πÅ‡∏•‡πâ‡∏ß‡∏î‡∏∂‡∏á‡∏Ñ‡∏π‡πà (berth_id, td_id) ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
    - ‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ //
    - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå‡∏ó‡πâ‡∏≤‡∏¢‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î (inline comment) ‡πÇ‡∏î‡∏¢‡∏ï‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏á // ‡∏≠‡∏≠‡∏Å‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
    """
    content = file.read()
    try:
        text = content.decode("utf-8", errors="ignore")
    except Exception:
        text = content.decode(errors="ignore")
    lines = text.splitlines()

    in_data = False
    rows = []
    for raw in lines:
        s = raw.strip()

        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ DATA
        if s.startswith("** DATA BEGINS HERE **"):
            in_data = True
            continue
        if not in_data or not s:
            continue

        # ‡∏Ç‡πâ‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á/ metadata
        if s.startswith("Version") or s.startswith("berth_id"):
            continue

        # --- ‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå‡∏ó‡∏±‡πâ‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î ---
        if s.startswith("//"):
            continue

        # --- ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå‡∏ó‡πâ‡∏≤‡∏¢‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î (inline comment) ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ ---
        cut = raw
        pos = cut.find("//")
        if pos > 0:  # ‡∏°‡∏µ // ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏ï‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
            cut = cut[:pos]

        # ‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡πÅ‡∏ó‡πá‡∏ö/‡∏°‡∏µ‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏õ‡∏ô)
        toks = [t.strip() for t in cut.split("\t") if t.strip() != ""]
        if not toks:
            continue

        berth_id = toks[0]
        td_id    = toks[-1]

        # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ‡πÄ‡∏®‡∏©‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå‡πÇ‡∏ú‡∏•‡πà‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÅ‡∏£‡∏Å
        if str(berth_id).startswith("//"):
            continue

        rows.append((str(berth_id).strip(), str(td_id).strip()))

    df = pd.DataFrame(rows, columns=["berth_id", "td_id"])
    return df


def parse_manual_list(text: str) -> set:
    """‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ space/comma/newline ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ã‡πá‡∏ï‡∏Ç‡∏≠‡∏á‡∏£‡∏´‡∏±‡∏™"""
    tokens = re.split(r"[,\s]+", (text or "").strip())
    return {t for t in tokens if t}


def compare_sets(name: str, dna_set: set, ref_set: set) -> pd.DataFrame:
    """‡∏Ñ‡∏∑‡∏ô DataFrame ‡∏ó‡∏µ‡πà‡∏°‡∏µ status = MISSING_IN_DNA / EXTRA_IN_DNA / MATCHED"""
    missing = sorted(ref_set - dna_set)  # ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô .dna
    extra   = sorted(dna_set - ref_set)  # ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô .dna ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á
    matched = sorted(dna_set & ref_set)

    parts = []
    parts += [{"td_id": name, "status": "MISSING_IN_DNA", "berth_id": bid} for bid in missing]
    parts += [{"td_id": name, "status": "EXTRA_IN_DNA",   "berth_id": bid} for bid in extra]
    parts += [{"td_id": name, "status": "MATCHED",        "berth_id": bid} for bid in matched]
    return pd.DataFrame(parts, columns=["td_id", "status", "berth_id"])


def _sanitize_filename(name: str) -> str:
    safe = re.sub(r"[^0-9A-Za-z._-]+", "_", name.strip())
    return safe or "TD"


def _back_to_home():
    st.session_state.page = "home"
    st.rerun()


def _prepare_td_files_from_uploads(dna_files, unique_only=True):
    """Parse multiple .dna files and build a list of dicts: {td_id, file_name, data(bytes), count}"""
    frames = []
    for f in dna_files:
        frames.append(parse_dna_file(f))
    if not frames:
        return []
    df = pd.concat(frames, ignore_index=True)
    if df.empty:
        return []

    td_files = []
    for td, grp in df.groupby("td_id"):
        values = grp["berth_id"].astype(str)
        if unique_only:
            values = pd.Index(values).unique()
            values = sorted(values)
        content = "\n".join(values) + ("\n" if len(values) else "")
        data = content.encode("utf-8")
        fname = f"{_sanitize_filename(str(td))}.txt"
        td_files.append({"td_id": str(td), "file_name": fname, "data": data, "count": len(values)})
    return sorted(td_files, key=lambda x: x["td_id"])


# ============== HOMEPAGE ==============
def render_home():
    st.title("DVS Tools ‚Ä¢ DCR Thailand")
    st.write("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

    c1, c2 = st.columns(2)
    with c1:
        if st.button("üè≠ DVS Producer (Berth sorter)", use_container_width=True):
            st.session_state.page = "producer"
            st.rerun()
    with c2:
        if st.button("üß™ DVS Checker", use_container_width=True):
            st.session_state.page = "checker"
            st.rerun()


# ============== DVS CHECKER (‡∏ï‡∏≤‡∏°‡πÅ‡∏≠‡∏õ‡πÄ‡∏î‡∏¥‡∏°) ==============
def render_checker():
    st.button("‚Üê ‡∏Å‡∏•‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏£‡∏Å", on_click=_back_to_home)
    st.title("DVS Checker")

    dna_files = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå berth.dna (‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ)", type=["dna", "txt"], accept_multiple_files=True)
    td_input = st.text_input("‡πÉ‡∏™‡πà‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ td_id ‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏Å‡∏î Enter", value="Y1 YE FE DR").strip()
    td_list = [t for t in td_input.split() if t]

    st.markdown("### ‡∏ß‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ td (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ space / comma / newline)")
    manual_map = {}
    cols = st.columns(2)
    for i, td in enumerate(td_list):
        with cols[i % 2]:
            manual_map[td] = st.text_area(
                f"{td} ‚Ä¢ ‡∏ß‡∏≤‡∏á `berth_id` ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πÄ‡∏õ‡∏Å",
                key=f"ta_{td}",
                height=120,
                placeholder="‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: A101, A102, A103 ‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ô‡πÄ‡∏ß‡πâ‡∏ô‡∏ß‡∏£‡∏£‡∏Ñ/‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î"
            )

    run_btn = st.button("üîé ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô")

    if run_btn:
        if not dna_files:
            st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå .dna ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡πÑ‡∏ü‡∏•‡πå")
            st.stop()

        frames = []
        for f in dna_files:
            try:
                frames.append(parse_dna_file(f))
            except Exception as e:
                st.error(f"‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {f.name} ({e})")
        if not frames:
            st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .dna ‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î")
            st.stop()

        df_all = pd.concat(frames, ignore_index=True)

        summary_rows = []
        per_td_results = {}
        warn_empty = []

        for td in td_list:
            dna_ids = set(df_all.loc[df_all["td_id"] == td, "berth_id"].astype(str))
            ref_ids = parse_manual_list(manual_map.get(td, ""))

            if len(ref_ids) == 0:
                warn_empty.append(td)

            result_df = compare_sets(td, dna_ids, ref_ids)
            per_td_results[td] = result_df

            n_miss  = (result_df["status"] == "MISSING_IN_DNA").sum()
            n_extra = (result_df["status"] == "EXTRA_IN_DNA").sum()
            n_match = (result_df["status"] == "MATCHED").sum()

            summary_rows.append({
                "td_id": td,
                "ref_count": len(ref_ids),
                "dna_count": len(dna_ids),
                "matched": n_match,
                "missing_in_dna": n_miss,
                "extra_in_dna": n_extra
            })

        if warn_empty:
            st.warning("td ‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ß‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á: " + ", ".join(warn_empty))

        summary = pd.DataFrame(summary_rows)
        st.subheader("üìä SUMMARY")
        st.dataframe(summary, use_container_width=True)

        st.subheader("üîé ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á (‡∏ï‡πà‡∏≠ td_id)")
        for td, dfres in per_td_results.items():
            col1, col2 = st.columns(2)
            with col1:
                st.markdown(f"**{td} ‚Äî MISSING_IN_DNA** (‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô .dna)")
                st.dataframe(
                    dfres.loc[dfres["status"] == "MISSING_IN_DNA", ["berth_id"]],
                    use_container_width=True, height=240
                )
            with col2:
                st.markdown(f"**{td} ‚Äî EXTRA_IN_DNA** (‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô .dna ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á)")
                st.dataframe(
                    dfres.loc[dfres["status"] == "EXTRA_IN_DNA", ["berth_id"]],
                    use_container_width=True, height=240
                )

        output = BytesIO()
        with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
            summary.to_excel(writer, sheet_name="SUMMARY", index=False)
            for td, dfres in per_td_results.items():
                sheet = td[:31] if td else "TD"
                dfres.to_excel(writer, sheet_name=sheet, index=False)
        output.seek(0)

        st.download_button(
            label="‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô Excel",
            data=output,
            file_name="td_compare_report.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

        st.success("‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        st.caption("Tips: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏™‡πÄ‡∏õ‡∏Å‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ td ‡πÑ‡∏ß‡πâ‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡πâ‡∏ß copy/paste ‡∏•‡∏á‡∏ä‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á td ‡∏ô‡∏±‡πâ‡∏ô ‡πÜ")


# ============== DVS PRODUCER (Persist results; Checkbox + one ZIP) ==============
def render_producer():
    st.button("‚Üê ‡∏Å‡∏•‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏£‡∏Å", on_click=_back_to_home)
    st.title("DVS Producer")

    dna_files = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå berth.dna (‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ)", type=["dna", "txt"], accept_multiple_files=True)
    unique_only = st.checkbox("‡∏•‡∏ö‡∏ã‡πâ‡∏≥‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡πà‡∏≤ (recommended)", value=True)
    produce_clicked = st.button("üèÅ Produce")

    # ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏î Produce ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÉ‡∏ô session_state ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏´‡∏≤‡∏¢‡∏ï‡∏≠‡∏ô rerun
    if produce_clicked:
        if not dna_files:
            st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå .dna ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡πÑ‡∏ü‡∏•‡πå")
            st.stop()
        try:
            td_files = _prepare_td_files_from_uploads(dna_files, unique_only=unique_only)
        except Exception as e:
            st.error(f"‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
            st.stop()

        if not td_files:
            st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .dna")
            st.stop()

        st.session_state["producer_td_files"] = td_files
        # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏´‡πâ‡∏ß‡πà‡∏≤‡∏á
        for it in td_files:
            st.session_state[f"sel_{it['file_name']}"] = False

    # ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô state ‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå + ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î ‡πÄ‡∏™‡∏°‡∏≠ (‡πÑ‡∏°‡πà‡∏´‡∏≤‡∏¢‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ rerun ‡∏à‡∏≤‡∏Å checkbox)
    td_files_state = st.session_state.get("producer_td_files", [])
    if td_files_state:
        st.subheader("üì¶ ‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠ td_id")
        st.dataframe(pd.DataFrame([{"td_id": x["td_id"], "count": x["count"]} for x in td_files_state]).sort_values("td_id").reset_index(drop=True), use_container_width=True)

        st.subheader("üóÇÔ∏è ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î")
        # ‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î/‡∏•‡πâ‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
        c1, c2, c3 = st.columns([1,1,2])
        with c1:
            if st.button("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"):
                for it in td_files_state:
                    st.session_state[f"sel_{it['file_name']}"] = True
                st.rerun()
        with c2:
            if st.button("‡∏•‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å"):
                for it in td_files_state:
                    st.session_state[f"sel_{it['file_name']}"] = False
                st.rerun()
        with c3:
            if st.button("‡∏•‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà)"):
                for it in td_files_state:
                    st.session_state.pop(f"sel_{it['file_name']}", None)
                st.session_state.pop("producer_td_files", None)
                st.rerun()

        # ‡πÅ‡∏™‡∏î‡∏á checkbox ‡πÅ‡∏ö‡∏ö 3 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà
        cols = st.columns(3)
        for i, item in enumerate(td_files_state):
            key = f"sel_{item['file_name']}"
            if key not in st.session_state:
                st.session_state[key] = False
            with cols[i % 3]:
                st.checkbox(f"{item['file_name']} ({item['count']})", key=key)

        
        # ‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß: ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏±‡∏ô‡∏ó‡∏µ (‡∏™‡∏£‡πâ‡∏≤‡∏á ZIP on-the-fly)
        selected_items = [it for it in td_files_state if st.session_state.get(f"sel_{it['file_name']}", False)]
        disabled = len(selected_items) == 0

        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° ZIP bytes ‡∏ï‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
        zip_bytes = b""
        zip_filename = "dvs_selected.zip"
        if not disabled:
            memzip = BytesIO()
            with zipfile.ZipFile(memzip, mode="w", compression=zipfile.ZIP_DEFLATED) as zf:
                for it in selected_items:
                    zf.writestr(it["file_name"], it["data"])
            memzip.seek(0)
            zip_bytes = memzip.getvalue()
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            zip_filename = f"dvs_selected_{ts}.zip"

        st.download_button(
            label="‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å",
            data=zip_bytes,
            file_name=zip_filename,
            mime="application/zip",
            use_container_width=True,
            disabled=disabled,
            key="dl_zip_selected"
        )
    


# ============== ROUTING ==============
if "page" not in st.session_state:
    st.session_state.page = "home"

if st.session_state.page == "home":
    render_home()
elif st.session_state.page == "checker":
    render_checker()
elif st.session_state.page == "producer":
    render_producer()
else:
    render_home()
